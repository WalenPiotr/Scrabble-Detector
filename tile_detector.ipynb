{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.15))\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 2, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "itr =  datagen.flow_from_directory(\n",
    "            './data_set_tile',\n",
    "            target_size=(64,64),\n",
    "            batch_size=1868,\n",
    "            class_mode='categorical')\n",
    "X, y = itr.next()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tile_classifier import load_data\n",
    "folder = './data_set_tile'\n",
    "X_train,X_test,y_train,y_test = load_data(folder)\n",
    "classifier.fit(X_train, y_train, epochs=5, batch_size=X_train.shape[0]//20,verbose = 1)\n",
    "classifier.save_weights('model.h5') \n",
    "classifier.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('./testy/002.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour(img):\n",
    "    grey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey,(7,7),0)\n",
    "    edges = cv2.Canny(blur,50,100,apertureSize = 3)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    dilation = cv2.dilate(edges,kernel,iterations = 2)\n",
    "    contour_img, contours, hierarchy = cv2.findContours(\n",
    "                                            dilation, \n",
    "                                            cv2.RETR_TREE,\n",
    "                                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = max(contours, key = cv2.contourArea)\n",
    "    contour_img = img.copy()\n",
    "    contour_img = cv2.drawContours(contour_img, [cnt], 0, (0,255,0), 3)\n",
    "    return contour_img, cnt\n",
    "\n",
    "contour_img, cnt = get_contour(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(cnt):\n",
    "    epsilon = 0.01*cv2.arcLength(cnt,True)\n",
    "    approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "    x_center = np.mean(approx[:,:,0])\n",
    "    y_center = np.mean(approx[:,:,1])\n",
    "\n",
    "    #sorting\n",
    "    pts = np.zeros((4,2))\n",
    "    for x in approx:\n",
    "        for X, Y in x:\n",
    "            if(X<x_center and Y<y_center):\n",
    "                pts[0,0] = X\n",
    "                pts[0,1] = Y\n",
    "            if(X<x_center and Y>y_center):\n",
    "                pts[1,0] = X\n",
    "                pts[1,1] = Y\n",
    "            if(X>x_center and Y>y_center):\n",
    "                pts[2,0] = X\n",
    "                pts[2,1] = Y\n",
    "            if(X>x_center and Y<y_center):\n",
    "                pts[3,0] = X\n",
    "                pts[3,1] = Y\n",
    "    size = max(approx.flatten()) - min(approx.flatten())\n",
    "    return pts, size\n",
    "\n",
    "pts, size = get_points(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(img, pts, size):\n",
    "    pts = np.float32(pts)\n",
    "    pts_sqr = np.float32([[0,0],[0,size],[size,size],[size,0]])\n",
    "    M = cv2.getPerspectiveTransform(pts,pts_sqr)\n",
    "    warped_img = cv2.warpPerspective(img,M,(size,size))\n",
    "    return warped_img\n",
    "board = warp_image(img, pts, size)\n",
    "warped_img = board[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_image(image):\n",
    "    slices = list()\n",
    "    samples_x = np.linspace(0,image.shape[0],16, dtype=np.int)\n",
    "    samples_y = np.linspace(0,image.shape[1],16,dtype=np.int)\n",
    "    for x_start, x_end in zip(samples_x, samples_x[1:]):\n",
    "        for y_start, y_end in zip(samples_y, samples_y[1:]):\n",
    "            slices.append(image[x_start:x_end,y_start:y_end])\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "slices = slice_image(warped_img)\n",
    "indexes = list()\n",
    "for slice_ in slices:\n",
    "    scaled_img = resize(slice_,(64,64,3),mode='reflect')\n",
    "    img = np.expand_dims(scaled_img, axis = 0)\n",
    "    prediction = classifier.predict(img)\n",
    "    indexes.append(np.argmax(prediction.flatten()))\n",
    "arr = np.array(indexes).reshape(15,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 10),dpi= 100)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xticks(range(0,15))                                                       \n",
    "ax.set_yticks(range(0,15))\n",
    "ax.imshow(arr, cmap = 'bwr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_indexes = [i for i, x in enumerate(indexy) if x == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
