{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "img = cv2.imread('./testy/000.jpg')\n",
    "plt.imshow(img[...,::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board detection\n",
    "def get_contour(img):\n",
    "    grey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey,(7,7),0)\n",
    "    edges = cv2.Canny(blur, 50, 100, apertureSize = 3)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    dilation = cv2.dilate(edges,kernel,iterations = 2)\n",
    "    contour_img, contours, hierarchy = cv2.findContours(\n",
    "                                            dilation, \n",
    "                                            cv2.RETR_TREE,\n",
    "                                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = max(contours, key = cv2.contourArea)\n",
    "    contour_img = img.copy()\n",
    "    contour_img = cv2.drawContours(contour_img, [cnt], 0, (0,255,0), 3)\n",
    "    return contour_img, cnt\n",
    "\n",
    "\n",
    "def get_points(cnt):\n",
    "    epsilon = 0.01*cv2.arcLength(cnt,True)\n",
    "    approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "    x_center = np.mean(approx[:,:,0])\n",
    "    y_center = np.mean(approx[:,:,1])\n",
    "\n",
    "    #sorting\n",
    "    pts = np.zeros((4,2))\n",
    "    for x in approx:\n",
    "        for X, Y in x:\n",
    "            if X < x_center and Y < y_center:\n",
    "                pts[0,0] = X\n",
    "                pts[0,1] = Y\n",
    "            if X < x_center and Y > y_center:\n",
    "                pts[1,0] = X\n",
    "                pts[1,1] = Y\n",
    "            if X > x_center and Y > y_center:\n",
    "                pts[2,0] = X\n",
    "                pts[2,1] = Y\n",
    "            if X > x_center and Y < y_center:\n",
    "                pts[3,0] = X\n",
    "                pts[3,1] = Y\n",
    "    size = max(approx.flatten()) - min(approx.flatten())\n",
    "    return pts, size\n",
    "\n",
    "\n",
    "def warp_image(img, pts, size):\n",
    "    pts = np.float32(pts)\n",
    "    pts_sqr = np.float32([[0,0],[0,size],[size,size],[size,0]])\n",
    "    M = cv2.getPerspectiveTransform(pts,pts_sqr)\n",
    "    warped_img = cv2.warpPerspective(img,M,(size,size))\n",
    "    return warped_img\n",
    "\n",
    "def warp_image(img, pts, size):\n",
    "    pts = np.float32(pts)\n",
    "    pts_sqr = np.float32([[0,0],[0,size],[size,size],[size,0]])\n",
    "    M = cv2.getPerspectiveTransform(pts,pts_sqr)\n",
    "    warped_img = cv2.warpPerspective(img,M,(size,size))\n",
    "    return warped_img\n",
    "\n",
    "def slice_image(image):\n",
    "    slices = list()\n",
    "    samples_x = np.linspace(0,image.shape[0],16, dtype=np.int)\n",
    "    samples_y = np.linspace(0,image.shape[1],16,dtype=np.int)\n",
    "    for x_start, x_end in zip(samples_x, samples_x[1:]):\n",
    "        for y_start, y_end in zip(samples_y, samples_y[1:]):\n",
    "            slices.append(image[x_start:x_end,y_start:y_end])\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_img, cnt = get_contour(img)\n",
    "pts, size = get_points(cnt)\n",
    "board = warp_image(img, pts, size)\n",
    "warped_img = board[...,::-1]\n",
    "plt.imshow(warped_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from skimage.transform import resize\n",
    "from skimage import color\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tile classifier setup, training\n",
    "tile_classifier = Sequential()\n",
    "tile_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "tile_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "tile_classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "tile_classifier.add(Dropout(0.15))\n",
    "tile_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "tile_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "tile_classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "tile_classifier.add(Flatten())\n",
    "tile_classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "tile_classifier.add(Dense(units = 2, activation = 'softmax'))\n",
    "tile_classifier.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "itr_tiles =  datagen.flow_from_directory(\n",
    "            './data_set_tile',\n",
    "            target_size=(64,64),\n",
    "            batch_size= 1868,\n",
    "            class_mode='categorical')\n",
    "X, y = itr_tiles.next()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=7)\n",
    "\n",
    "# tile_classifier.fit(X_train, y_train, epochs=5, batch_size=X_train.shape[0]//20,verbose = 1)\n",
    "# tile_classifier.save_weights('tile_detector.h5') \n",
    "tile_classifier.load_weights('tile_detector.h5')\n",
    "# tile_classifier.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_classifier = Sequential()\n",
    "\n",
    "letter_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "letter_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "letter_classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "letter_classifier.add(Dropout(0.15))\n",
    "\n",
    "letter_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "letter_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "letter_classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "letter_classifier.add(Dropout(0.15))\n",
    "\n",
    "letter_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "letter_classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "letter_classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "letter_classifier.add(Flatten())\n",
    "letter_classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "letter_classifier.add(Dense(units = 33, activation = 'softmax'))\n",
    "\n",
    "letter_classifier.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "datagen = ImageDataGenerator(\n",
    "                rescale=1. / 255, \n",
    "                rotation_range=10,\n",
    "                width_shift_range = 0.1,\n",
    "                height_shift_range = 0.1)\n",
    "itr_letters =  datagen.flow_from_directory(\n",
    "            './data_set_letter',\n",
    "            target_size=(64,64),\n",
    "            batch_size= 812,\n",
    "            class_mode='categorical')\n",
    "\n",
    "X, y = itr_letters.next()\n",
    "for i in range(5):\n",
    "    X_temp,y_temp = itr_letters.next()\n",
    "    X = np.vstack((X,X_temp))\n",
    "    y = np.vstack((y,y_temp))\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=7)\n",
    "\n",
    "# letter_classifier.fit(X_train, y_train, epochs=20, batch_size=X_train.shape[0]//20,verbose = 1)\n",
    "# letter_classifier.save_weights('letters_classifier.h5') \n",
    "letter_classifier.load_weights('letters_classifier.h5')\n",
    "letter_classifier.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "slices = slice_image(warped_img)\n",
    "predictions = list()\n",
    "for slice_ in slices:\n",
    "    scaled_img = resize(slice_,(64,64,3),mode='reflect')\n",
    "    img = np.expand_dims(scaled_img, axis = 0)\n",
    "    tile_prediction = tile_classifier.predict(img)\n",
    "    class_prediction = np.argmax(tile_prediction.flatten()) - 1\n",
    "    if(class_prediction == 0):\n",
    "        letter_prediction = letter_classifier.predict(img)\n",
    "        class_prediction = np.argmax(letter_prediction)\n",
    "    predictions.append(class_prediction)\n",
    "    \n",
    "predictions_board = np.array(predictions).reshape(15,15)\n",
    "print(predictions_board)\n",
    "# tile_indexes = [i for i, x in enumerate(indexes) if x == 1]\n",
    "# letter_slices = np.array(slices)[tile_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = itr_letters.class_indices\n",
    "mapping.update({'_':-1,\n",
    "                'x':0})\n",
    "inverse_mapping = {v:k[:1] for k, v in mapping.items()}\n",
    "mapped_board = np.vectorize(inverse_mapping.get)(predictions_board)\n",
    "print(mapped_board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_indexes = []\n",
    "for letter_slice in letter_slices:\n",
    "    scaled_img = resize(letter_slice,(64,64,3),mode='reflect')\n",
    "    img = np.expand_dims(scaled_img, axis = 0)\n",
    "    prediction = letter_classifier.predict(img)\n",
    "    letter_indexes.append(np.argmax(prediction.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5),dpi= 100)\n",
    "plt.imshow(predictions_board)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
